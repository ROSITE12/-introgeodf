{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rq_-jS9HtUU-"
      },
      "source": [
        "<img src=\"https://i.imgur.com/6U6q5jQ.png\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cCaZ1r2tUVA"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/SocialAnalytics-StrategicIntelligence/GeoDFBasics_py/blob/main/index.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "# The Geo Dataframe\n",
        "\n",
        "The geodataframe (GDF) is a dataframe (DF) where every row represents an spatial element (point, line, polygon).\n",
        "\n",
        "Historically, the most common file type that stores spatial elements is the shapefile. Let's take a look at some of them:\n",
        "\n",
        "1. In GitHub (cloud), create a repository named: introgeodf.\n",
        "2. Clone that repo to a local folder in your computer.\n",
        "3. In that local folder in your computer, create a folder named **maps**.\n",
        "4. Go to paidea and download three compressed files.\n",
        "5. Download those files into the folder **maps** in your computer: *countries*, *cities*, and *rivers*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhGJmen1tUVB"
      },
      "source": [
        "You may see something like this:\n",
        "\n",
        "<img src=\"https://github.com/CienciaDeDatosEspacial/code_and_data/blob/main/mapsFolderImage.png?raw=true\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBs3ovRstUVB"
      },
      "source": [
        "You can decompress those files:\n",
        "\n",
        "<img title=\"a title\" alt=\"Alt text\" src=\"https://github.com/CienciaDeDatosEspacial/code_and_data/blob/main/folderRar_1.png?raw=true\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzvFDa2JtUVB"
      },
      "source": [
        "Now, take a look a **World_Countries**:\n",
        "\n",
        "<img src=\"https://github.com/CienciaDeDatosEspacial/code_and_data/blob/main/imageCountries_shp.png?raw=true\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUOIWMOTtUVB"
      },
      "source": [
        "There, you see that this **one map** requires **several files**. That is the nature of the shapefile.\n",
        "\n",
        "Let's read the file with the help of **geopandas**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KJV5G0POtUVB"
      },
      "outputs": [
        {
          "ename": "DataSourceError",
          "evalue": "maps\\World_Countries\\World_Countries.shp: No such file or directory",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mDataSourceError\u001b[0m                           Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mgeopandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m countries\u001b[38;5;241m=\u001b[39m\u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWorld_Countries\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWorld_Countries.shp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\geopandas\\io\\file.py:294\u001b[0m, in \u001b[0;36m_read_file\u001b[1;34m(filename, bbox, mask, columns, rows, engine, **kwargs)\u001b[0m\n\u001b[0;32m    291\u001b[0m             from_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyogrio\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read_file_pyogrio\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiona\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_file_like(filename):\n",
            "File \u001b[1;32mc:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\geopandas\\io\\file.py:547\u001b[0m, in \u001b[0;36m_read_file_pyogrio\u001b[1;34m(path_or_bytes, bbox, mask, rows, **kwargs)\u001b[0m\n\u001b[0;32m    538\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    539\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minclude_fields\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore_fields\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keywords are deprecated, and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    540\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future release. You can use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keyword \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    543\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m    544\u001b[0m     )\n\u001b[0;32m    545\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude_fields\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 547\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpyogrio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyogrio\\geopandas.py:261\u001b[0m, in \u001b[0;36mread_dataframe\u001b[1;34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, fid_as_index, use_arrow, on_invalid, arrow_to_pandas_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_arrow:\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;66;03m# For arrow, datetimes are read as is.\u001b[39;00m\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;66;03m# For numpy IO, datetimes are read as string values to preserve timezone info\u001b[39;00m\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# as numpy does not directly support timezones.\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetime_as_string\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 261\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mread_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mread_geometry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_geometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgdal_force_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql_dialect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql_dialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_fids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfid_as_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_arrow:\n\u001b[0;32m    281\u001b[0m     meta, table \u001b[38;5;241m=\u001b[39m result\n",
            "File \u001b[1;32mc:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyogrio\\raw.py:196\u001b[0m, in \u001b[0;36mread\u001b[1;34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, return_fids, datetime_as_string, **kwargs)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Read OGR data source into numpy arrays.\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \n\u001b[0;32m     58\u001b[0m \u001b[38;5;124;03mIMPORTANT: non-linear geometry types (e.g., MultiSurface) are converted\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    191\u001b[0m \n\u001b[0;32m    192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    194\u001b[0m dataset_kwargs \u001b[38;5;241m=\u001b[39m _preprocess_options_key_value(kwargs) \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m--> 196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mogr_read\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_vsi_path_or_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mread_geometry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_geometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_mask_to_wkb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql_dialect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql_dialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_fids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_fids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatetime_as_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatetime_as_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyogrio\\_io.pyx:1239\u001b[0m, in \u001b[0;36mpyogrio._io.ogr_read\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyogrio\\_io.pyx:219\u001b[0m, in \u001b[0;36mpyogrio._io.ogr_open\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mDataSourceError\u001b[0m: maps\\World_Countries\\World_Countries.shp: No such file or directory"
          ]
        }
      ],
      "source": [
        "import os, geopandas as gpd\n",
        "\n",
        "countries=gpd.read_file(os.path.join(\"maps\",\"World_Countries\",\"World_Countries.shp\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5AOj3mktUVC"
      },
      "source": [
        "Let's use some familiar DF functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTVBGfNatUVC"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mUnable to start Kernel 'Python 3.12.5' due to a timeout waiting for the ports to get used. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# what is it?\n",
        "type(countries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkvWskZytUVC"
      },
      "outputs": [],
      "source": [
        "# dimensions\n",
        "countries.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETJdBBR1tUVD"
      },
      "outputs": [],
      "source": [
        "# names\n",
        "countries.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrbZt4g5tUVD"
      },
      "outputs": [],
      "source": [
        "# some content\n",
        "countries.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPHdGEtatUVD"
      },
      "outputs": [],
      "source": [
        "# any missing values?\n",
        "countries[countries.isna().any(axis=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWXmBv-vtUVD",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# types\n",
        "countries.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzT4ctrjtUVD"
      },
      "source": [
        "As you see, every pandas command is working, but now we have a new column type: **geometry**. Let's see this map of countries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjMj9myHtUVD"
      },
      "outputs": [],
      "source": [
        "countries.plot(facecolor=\"azure\",#color of polygon fill\n",
        "               edgecolor='black', #color of lines\n",
        "               linewidth=0.1) #thickness of lines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCtifGnqtUVD"
      },
      "source": [
        "Let's open the other maps:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPbJ4wFHtUVD"
      },
      "outputs": [],
      "source": [
        "rivers=gpd.read_file(os.path.join(\"maps\",\"World_Hydrography\",\"World_Hydrography.shp\"))\n",
        "cities=gpd.read_file(os.path.join(\"maps\",\"World_Cities\",\"World_Cities.shp\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjsfOdIWAyzT"
      },
      "source": [
        "This is the rivers map:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Gap_au4tUVD"
      },
      "outputs": [],
      "source": [
        "rivers.plot(edgecolor='blue',\n",
        "            linewidth=1,\n",
        "            linestyle='dotted')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMt1VW77AyzT"
      },
      "source": [
        "This is the cities map:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nAC2GkptUVD"
      },
      "outputs": [],
      "source": [
        "cities.plot(marker='.', # marker type\n",
        "            color='red',\n",
        "            markersize=1,\n",
        "            alpha=0.3) # transparency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prkK6IA8tUVE"
      },
      "source": [
        "You can plot all the layers, as long as they share the same projection.\n",
        "Let's verify that all have the same projection (**CRS**):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8G0MkpZ1tUVE"
      },
      "outputs": [],
      "source": [
        "countries.crs==cities.crs==cities.crs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOiFM3uYtUVE"
      },
      "source": [
        "You can start by creating the layer on the back (the base), and add layers on top:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqkVAvHstUVE"
      },
      "outputs": [],
      "source": [
        "base = countries.plot(facecolor=\"white\",\n",
        "                      edgecolor='black',\n",
        "                      linewidth=0.1,\n",
        "                      figsize=(12,12))\n",
        "\n",
        "rivers.plot(edgecolor='blue', linewidth=0.4,\n",
        "            ax=base)# on top of...\n",
        "cities.plot(marker='.', color='red', markersize=1,alpha=0.7,\n",
        "            ax=base) # on top of...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHAklrjLAyzU"
      },
      "outputs": [],
      "source": [
        "countries.to_file(os.path.join(\"maps\",\"worldMap.gpkg\"),layer='countryBorders', driver=\"GPKG\")\n",
        "rivers.to_file(os.path.join(\"maps\",\"worldMap.gpkg\"),layer='riverLines', driver=\"GPKG\")\n",
        "cities.to_file(os.path.join(\"maps\",\"worldMap.gpkg\"),layer='cityPoints', driver=\"GPKG\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WVBq3bUtUVE"
      },
      "source": [
        "## Subsetting\n",
        "\n",
        "You can subset your map by *filtering*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsiI-8ZYtUVE"
      },
      "outputs": [],
      "source": [
        "brazil=countries[countries.COUNTRY=='Brazil']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biux_VKutUVF"
      },
      "source": [
        "But you can also subset by *clipping*, as sometimes other data frames may not have the same fields for filtering:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltxxI2OotUVF"
      },
      "outputs": [],
      "source": [
        "citiesBrazil_clipped = gpd.clip(gdf=cities,\n",
        "                          mask=brazil)\n",
        "riversBrazil_clipped = gpd.clip(gdf=rivers,\n",
        "                               mask=brazil)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nXd5aiRtUVF"
      },
      "source": [
        "Then, you can plot the clipped version:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEfKc5nQtUVF"
      },
      "outputs": [],
      "source": [
        "base = brazil.plot(facecolor=\"greenyellow\", edgecolor='black', linewidth=0.4,figsize=(5,5))\n",
        "citiesBrazil_clipped.plot(marker='+', color='red', markersize=15,\n",
        "                    ax=base)\n",
        "riversBrazil_clipped.plot(edgecolor='blue', linewidth=0.5,\n",
        "                    ax=base)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-fyudjGAyzW"
      },
      "source": [
        "You can also check what geometries you have in your GDF:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vegfi-vnAyzW"
      },
      "outputs": [],
      "source": [
        "brazil.geom_type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUZgiiU8AyzW"
      },
      "outputs": [],
      "source": [
        "citiesBrazil_clipped.geom_type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWGQuFFoAyzX",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "riversBrazil_clipped.geom_type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TNHFiA0AyzX"
      },
      "source": [
        "Notice that the amount of elements (rows) is different, and that all those elements do not belong to the exact geometry type."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV9H7DX8AyzX"
      },
      "source": [
        "<a class=\"anchor\" id=\"1\"></a>\n",
        "\n",
        "## Map Projection\n",
        "\n",
        "The CRS is a very important property of the maps. They affect three aspects:\n",
        "\n",
        "* shape\n",
        "* area\n",
        "* scale\n",
        "* direction\n",
        "\n",
        "Most maps come with a default CRS: 4326. Pay attention:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-iqIihNAyzX"
      },
      "outputs": [],
      "source": [
        "# check units\n",
        "brazil.crs.axis_info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6uY0EBlAyzX"
      },
      "source": [
        "Polygons have a centroid. When we try getting a centroid from an **unprojected** polygon, you get:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUqZchpmAyzY"
      },
      "outputs": [],
      "source": [
        "# centroid\n",
        "brazil.centroid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCNj0_dCAyzY"
      },
      "source": [
        "### Reprojecting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyQQ6FMQAyzY"
      },
      "source": [
        "A projected CRS will have units in meters or feet (or similar). You can request a crs per country [here](https://epsg.io/?q=brazil+kind%3APROJCRS):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4Cxfb0gAyzY"
      },
      "outputs": [],
      "source": [
        "# recommended for Brazil (meters)\n",
        "brazil.to_crs(5641).crs.axis_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4WOyHnjAyzY"
      },
      "outputs": [],
      "source": [
        "# now this works\n",
        "brazil.to_crs(5641).centroid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSh9b_88AyzZ"
      },
      "outputs": [],
      "source": [
        "# replotting:\n",
        "\n",
        "base5641=brazil.to_crs(5641).plot()\n",
        "brazil.to_crs(5641).centroid.plot(color='red',ax=base5641)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcwFWVgfAyzZ"
      },
      "source": [
        "Let's keep the projected version for all our maps:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Mp8b_agAyza"
      },
      "outputs": [],
      "source": [
        "brazil_5641=brazil.to_crs(5641)\n",
        "\n",
        "cities_brazil_5641=citiesBrazil_clipped.to_crs(brazil_5641.crs)\n",
        "\n",
        "rivers_brazil_5641=riversBrazil_clipped.to_crs(brazil_5641.crs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GR4nK91Ayza"
      },
      "outputs": [],
      "source": [
        "# saving\n",
        "import os\n",
        "\n",
        "brazil_5641.to_file(os.path.join(\"maps\",\"brazilMaps_5641.gpkg\"), layer='country', driver=\"GPKG\")\n",
        "cities_brazil_5641.to_file(os.path.join(\"maps\",\"brazilMaps_5641.gpkg\"), layer='cities', driver=\"GPKG\")\n",
        "rivers_brazil_5641.to_file(os.path.join(\"maps\",\"brazilMaps_5641.gpkg\"), layer='rivers', driver=\"GPKG\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbZh-z9CAyzb"
      },
      "outputs": [],
      "source": [
        "brazil_5641.centroid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4m_36IZAyzb"
      },
      "outputs": [],
      "source": [
        "brazil_5641.centroid.to_file(os.path.join(\"maps\",\"brazilMaps_5641.gpkg\"), layer='centroid', driver=\"GPKG\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pVbQTdpAyzb"
      },
      "source": [
        "<a class=\"anchor\" id=\"3\"></a>\n",
        "\n",
        "## Creating Spatial data\n",
        "\n",
        "You will get Lines and Polygons as maps for sure, but that may not be the case with points. Let me download a **CSV** file with information on the airports in Brazil from this [website](https://data.humdata.org/dataset/ourairports-bra), I will save it in my **data** folder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLp4OCH8Ayzc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "infoairports=pd.read_csv(os.path.join(\"data\",\"br-airports.csv\"))\n",
        "\n",
        "# some rows\n",
        "\n",
        "infoairports.iloc[[0,1,2,3,-4,-3,-2,-1],:] #head and tail"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hblXntz_Ayzc"
      },
      "source": [
        "This needs some cleaning:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5r1NnsK_Ayzc"
      },
      "outputs": [],
      "source": [
        "# bye first row\n",
        "infoairports.drop(index=0,inplace=True)\n",
        "infoairports.reset_index(drop=True, inplace=True)\n",
        "infoairports.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ety2AEg4Ayzc"
      },
      "outputs": [],
      "source": [
        "# keep the  columns needed\n",
        "\n",
        "infoairports.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dA6_XD2FAyzc"
      },
      "outputs": [],
      "source": [
        "keep=['name','type','latitude_deg', 'longitude_deg','elevation_ft','region_name','municipality']\n",
        "infoairports=infoairports.loc[:,keep]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lI3Y31GlAyzd"
      },
      "outputs": [],
      "source": [
        "infoairports.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7o-l4EuwAyzd"
      },
      "source": [
        "Some formatting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xvacs10Ayzd"
      },
      "outputs": [],
      "source": [
        "numericCols=['latitude_deg', 'longitude_deg','elevation_ft']\n",
        "infoairports[numericCols]=infoairports.loc[:,numericCols].apply(lambda x:pd.to_numeric(x))\n",
        "\n",
        "# now\n",
        "infoairports.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rXD42tbAyzd"
      },
      "outputs": [],
      "source": [
        "# let's plot\n",
        "\n",
        "base = brazil_5641.plot(color='white', edgecolor='black') #unprojected\n",
        "\n",
        "infoairports.plot.scatter(x = 'longitude_deg', y = 'latitude_deg',ax=base)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kth_Ae2VAyze"
      },
      "source": [
        "Why is it wrong?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7T4O-HCAyzx"
      },
      "outputs": [],
      "source": [
        "airports=gpd.GeoDataFrame(data=infoairports.copy(),\n",
        "                 geometry=gpd.points_from_xy(infoairports.longitude_deg,\n",
        "                                             infoairports.latitude_deg),\n",
        "                 crs=brazil.crs.to_epsg())# the coordinates were in degrees - unprojected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GC52g7NKAyzy"
      },
      "outputs": [],
      "source": [
        "# does it look better?\n",
        "\n",
        "# let's plot\n",
        "\n",
        "base = brazil_5641.plot(color='white', edgecolor='black')\n",
        "airports.plot(ax=base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uw0hFVOCAyzz"
      },
      "outputs": [],
      "source": [
        "#remember:\n",
        "type(airports), type(infoairports)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-2O7zjkAyzz"
      },
      "source": [
        "Let's keep the projected version:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xm_zJeC1Ayzz"
      },
      "outputs": [],
      "source": [
        "airports_5641=airports.to_crs(5641)\n",
        "\n",
        "## then\n",
        "\n",
        "base = brazil_5641.plot(color='white', edgecolor='black')\n",
        "airports_5641.plot(ax=base)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MpJdbNmAyzz"
      },
      "source": [
        "Remember you have type of airports:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYkqQ_0pAyz0"
      },
      "outputs": [],
      "source": [
        "airports_5641['type'].value_counts() # this will not work: airports.type.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgHtEDOhAyz0"
      },
      "source": [
        "We may use that in the future. For now, just rename the **type** column to a different one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1dKj0dcAyz0"
      },
      "outputs": [],
      "source": [
        "airports_5641.rename(columns={'type':'kind'},inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fot3fOCdAyz0"
      },
      "outputs": [],
      "source": [
        "# adding the airports\n",
        "airports_5641.to_file(os.path.join(\"maps\",\"brazilMaps_5641.gpkg\"), layer='airports', driver=\"GPKG\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNMKrU-rAyz0"
      },
      "source": [
        "## Geo Merging\n",
        "\n",
        "Remember we have these data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHVCSDpZAyz0"
      },
      "outputs": [],
      "source": [
        "countries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b8OPOPVAyz1"
      },
      "source": [
        "This map has no interesting information beyond the geometry. Let me bring this info:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9k3Ol6HAyz1"
      },
      "outputs": [],
      "source": [
        "fragilityLink=\"https://github.com/SocialAnalytics-StrategicIntelligence/TableOperations/raw/main/dataFiles/fragility/fragilityCoded_2012_2023.pkl\"\n",
        "\n",
        "fragility=pd.read_pickle(fragilityLink)\n",
        "\n",
        "fragility.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6q0j84YuAyz1"
      },
      "source": [
        "We want to add the fragility data into the map. That is the merging process.\n",
        "For that, we need a common column. The country names is the option."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NABqzN33Ayz1"
      },
      "outputs": [],
      "source": [
        "# to upper case.\n",
        "countries['COUNTRY']=countries.COUNTRY.str.upper()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5-adegLAyz1"
      },
      "source": [
        "It is very unlikely the names are written the same. Verify:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJ-CkiWtAyz2"
      },
      "outputs": [],
      "source": [
        "onlyFragil=set(fragility.Country)- set(countries.COUNTRY)\n",
        "onlyMap=set(countries.COUNTRY)- set(fragility.Country)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whEDeQ1uAyz2"
      },
      "source": [
        "Check here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9dEumiaAyz2"
      },
      "outputs": [],
      "source": [
        "onlyFragil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__r4Z9nKAyz2"
      },
      "outputs": [],
      "source": [
        "# and here\n",
        "onlyMap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcJsXTxJAyz3"
      },
      "source": [
        "## Fuzzy merging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hck2mQe0Ayz3"
      },
      "source": [
        "Let's find similar names:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzEEcZ4aAyz3"
      },
      "outputs": [],
      "source": [
        "from thefuzz import process\n",
        "\n",
        "[(country, process.extractOne(country,onlyMap)) for country in sorted(onlyFragil)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBz-AbMuAyz3"
      },
      "outputs": [],
      "source": [
        "# subsetting\n",
        "[(country, process.extractOne(country,onlyMap)) for country in sorted(onlyFragil)\n",
        " if process.extractOne(country,onlyMap)[1]>=90]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHxoHOz7Ayz3"
      },
      "source": [
        "Preparing a _dict_ of changes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISPUlZUrAyz3"
      },
      "outputs": [],
      "source": [
        "# then:\n",
        "try1={country: process.extractOne(country,onlyMap)[0] for country in sorted(onlyFragil)\n",
        " if process.extractOne(country,onlyMap)[1]>=90}\n",
        "try1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_w9OJfgAyz4"
      },
      "source": [
        "Making changes and updating:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpHXiaSMAyz4"
      },
      "outputs": [],
      "source": [
        "fragility.Country.replace(try1,inplace=True)\n",
        "\n",
        "# updating\n",
        "onlyFragil=set(fragility.Country)- set(countries.COUNTRY)\n",
        "onlyMap=set(countries.COUNTRY)- set(fragility.Country)\n",
        "\n",
        "# new matches\n",
        "[(country, process.extractOne(country,onlyMap)) for country in sorted(onlyFragil)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ja1hjb5-Ayz4"
      },
      "outputs": [],
      "source": [
        "# then:\n",
        "try2={country: process.extractOne(country,onlyMap)[0] for country in sorted(onlyFragil)\n",
        " if process.extractOne(country,onlyMap)[1]!=60}\n",
        "try2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzpbCmJLAyz5"
      },
      "outputs": [],
      "source": [
        "# changing\n",
        "fragility.Country.replace(try2,inplace=True)\n",
        "\n",
        "# new update\n",
        "onlyFragil=set(fragility.Country)- set(countries.COUNTRY)\n",
        "onlyMap=set(countries.COUNTRY)- set(fragility.Country)\n",
        "\n",
        "# new matches\n",
        "[(country, process.extractOne(country,onlyMap)) for country in sorted(onlyFragil)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGO69PsLAyz5"
      },
      "source": [
        "At this stage, we go manual:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMbKKGDqAyz5"
      },
      "outputs": [],
      "source": [
        "fragility.Country.replace({'ESWATINI': 'SWAZILAND'},inplace=True)\n",
        "\n",
        "#\n",
        "onlyFragil=set(fragility.Country)- set(countries.COUNTRY)\n",
        "onlyMap=set(countries.COUNTRY)- set(fragility.Country)\n",
        "\n",
        "#\n",
        "[(country, process.extractOne(country,onlyMap)) for country in sorted(onlyFragil)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0qmRTrNAyz5"
      },
      "source": [
        "We can not improve the situation.\n",
        "\n",
        "Now, when you merge a GDF with a DF, **the GDF has to be on the left**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fO4ct67mAyz6"
      },
      "outputs": [],
      "source": [
        "theMapAndData=countries.merge(fragility,left_on='COUNTRY', right_on='Country')\n",
        "# here it is (new map):\n",
        "theMapAndData.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKb1lklUAyz6"
      },
      "source": [
        "# Choropleths\n",
        "\n",
        "We should plan how to color the polygons based on some variable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Te5zJSyhAyz7"
      },
      "outputs": [],
      "source": [
        "theMapAndData['Total_mnmx'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxcY_xw4Ay1E"
      },
      "outputs": [],
      "source": [
        "theMapAndData.boxplot(column=['Total_mnmx'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWNpX296Ay1E"
      },
      "outputs": [],
      "source": [
        "theMapAndData['Total_mnmx'].hist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGXGvzscAy1F"
      },
      "source": [
        "Let's see other possibilities to cut the data (instead of the amount of intervals presented in the histogram), but please install [**numba**](https://numba.readthedocs.io/en/stable/user/installing.html) before runing the next code; also make sure you have **pysal**, **mapclassify** and **numpy** installed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4XF8gI4Ay1F"
      },
      "outputs": [],
      "source": [
        "pip show numba pysal mapclassify numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xl_DMCnvAy1G"
      },
      "outputs": [],
      "source": [
        "import mapclassify\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(12345) # so we all get the same results!\n",
        "\n",
        "# let's try 5 intervals\n",
        "K=5\n",
        "theVar=theMapAndData.Total_mnmx\n",
        "# same interval width, easy interpretation\n",
        "ei5 = mapclassify.EqualInterval(theVar, k=K)\n",
        "# same interval width based on standard deviation, easy - but not as the previous one, poor when high skewness\n",
        "msd = mapclassify.StdMean(theVar)\n",
        "# interval width varies, counts per interval are close, not easy to grasp, repeated values complicate cuts\n",
        "q5=mapclassify.Quantiles(theVar,k=K)\n",
        "\n",
        "# based on similarity, good for multimodal data\n",
        "mb5 = mapclassify.MaximumBreaks(theVar, k=K)\n",
        "# based on similarity, good for skewed data\n",
        "ht = mapclassify.HeadTailBreaks(theVar) # no K needed\n",
        "# based on similarity, optimizer\n",
        "fj5 = mapclassify.FisherJenks(theVar, k=K)\n",
        "# based on similarity, optimizer\n",
        "jc5 = mapclassify.JenksCaspall(theVar, k=K)\n",
        "# based on similarity, optimizer\n",
        "mp5 = mapclassify.MaxP(theVar, k=K)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-f2hJMQAy1H"
      },
      "source": [
        "How can we select the right classification?\n",
        "Let me use the the Absolute deviation around class median (ADCM) to make the comparisson:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xM-6TvcVAy1H"
      },
      "outputs": [],
      "source": [
        "class5 = ei5,msd, q5,mb5,  ht, fj5, jc5, mp5\n",
        "# Collect ADCM for each classifier\n",
        "fits = np.array([ c.adcm for c in class5])\n",
        "# Convert ADCM scores to a DataFrame\n",
        "adcms = pd.DataFrame(fits)\n",
        "# Add classifier names\n",
        "adcms['classifier'] = [c.name for c in class5]\n",
        "# Add column names to the ADCM\n",
        "adcms.columns = ['ADCM', 'Classifier']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUUtfi6sAy1I"
      },
      "source": [
        "Now, plot the **adcms**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_swFfrqxAy1I"
      },
      "outputs": [],
      "source": [
        "adcms.sort_values('ADCM').plot.barh(x='Classifier')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OQdvZ_QAy1J"
      },
      "source": [
        "Let's save the best three strategies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOcIlqrPAy1J"
      },
      "outputs": [],
      "source": [
        "theMapAndData.loc[:,'Total_ei5'] = ei5.yb\n",
        "theMapAndData.loc[:,'Total_fj5'] = fj5.yb\n",
        "theMapAndData.loc[:,'Total_jc5'] = jc5.yb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TgmC_s3Ay1J"
      },
      "outputs": [],
      "source": [
        "# there you are\n",
        "theMapAndData.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkIcW2XqAy1K"
      },
      "source": [
        "Let's check the mean of 'Total_mnmx' by the labels of the columns created (from '0' to '4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUV0-IzMAy1K"
      },
      "outputs": [],
      "source": [
        "indexList=['Total_ei5','Total_fj5','Total_jc5']\n",
        "aggregator={'Total_mnmx': ['mean']}\n",
        "\n",
        "pd.concat([theMapAndData[['Total_mnmx',col]].groupby(col,as_index=False).agg(aggregator) for col in indexList],axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgoGliTRAy1K"
      },
      "source": [
        "Verify data types:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h84yN5nuAy1K"
      },
      "outputs": [],
      "source": [
        "theMapAndData.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGowVC7lAy1L"
      },
      "source": [
        "Let me create a copy of those columns with new names:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6rXToNGAy1L"
      },
      "outputs": [],
      "source": [
        "newColNames=[ name+\"_cat\" for name in indexList]\n",
        "\n",
        "theMapAndData[newColNames]=theMapAndData.loc[:,indexList]\n",
        "theMapAndData.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ayo2j49Ay1L"
      },
      "outputs": [],
      "source": [
        "# renaming\n",
        "newLabelsForLevels={0:\"0_Great\", 1:\"1_Good\", 2:\"2_Middle\", 3:\"3_Bad\", 4:\"4_Poor\"}\n",
        "\n",
        "theMapAndData[newColNames]=theMapAndData.loc[:,newColNames].replace(newLabelsForLevels)\n",
        "theMapAndData.drop(columns=['Country'],inplace=True)\n",
        "theMapAndData"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_smywTdlAy1L"
      },
      "source": [
        "We are ready for a choropleth:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGeUcXVXAy1M"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "f, ax = plt.subplots(1, figsize=(10, 10))\n",
        "theMapAndData.plot(column='Total_ei5', # variable to plot\n",
        "                   cmap='viridis', # set of colors\n",
        "                   categorical=True, # can be interpreted as category\n",
        "                   edgecolor='white', # border color\n",
        "                   linewidth=0., # width of border\n",
        "                   alpha=1, # level of transparency (0 is invisible)\n",
        "                   legend=True, # need a legend?\n",
        "                   # location of legend: 'best', 'upper right', 'upper left', 'lower left',\n",
        "                   # 'lower right', 'right', 'center left', 'center right',\n",
        "                   # 'lower center', 'upper center', 'center'\n",
        "                   legend_kwds={'loc':\"lower left\"},\n",
        "        ax=ax\n",
        "       )\n",
        "\n",
        "ax.set_axis_off()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ofjlp6nzAy1M"
      },
      "outputs": [],
      "source": [
        "# alternatively:\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "f, ax = plt.subplots(1, figsize=(10, 10))\n",
        "theMapAndData.plot(column='Total_ei5_cat', # annotated\n",
        "        cmap='viridis',\n",
        "        categorical=True,\n",
        "        edgecolor='white',\n",
        "        linewidth=0.,\n",
        "        alpha=1,\n",
        "        legend=True,\n",
        "        legend_kwds={'loc':3},\n",
        "        ax=ax\n",
        "       )\n",
        "\n",
        "ax.set_axis_off()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPa0L5srAy1M"
      },
      "source": [
        "Once you know the ADCM, you can request the choropleth without creating a variable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDYSjqrqAy1M"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "f, ax = plt.subplots(1, figsize=(10, 10))\n",
        "theMapAndData.plot(column='Total_mnmx',\n",
        "        cmap='viridis',\n",
        "                   scheme=\"equal_interval\",\n",
        "        edgecolor='white',\n",
        "        linewidth=0.,\n",
        "        alpha=0.75,\n",
        "        legend=True,\n",
        "        legend_kwds={'loc':3},\n",
        "        ax=ax\n",
        "       )\n",
        "\n",
        "ax.set_axis_off()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SDrcD_FAy1M"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "f, ax = plt.subplots(1, figsize=(10, 10))\n",
        "theMapAndData.plot(column='Total_ei5_cat',\n",
        "        cmap='viridis',\n",
        "        categorical=True,\n",
        "        edgecolor='white',\n",
        "        linewidth=0.,\n",
        "        alpha=0.75,\n",
        "        legend=True,\n",
        "        legend_kwds={'loc':\"lower right\"},\n",
        "        ax=ax\n",
        "       )\n",
        "\n",
        "ax.set_axis_off()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NABKLKpEAy1N"
      },
      "source": [
        "Let's save our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUmkRV8RAy1N"
      },
      "outputs": [],
      "source": [
        "theMapAndData.to_file(os.path.join(\"maps\",\"theMapAndData.gpkg\"), layer='fragility', driver=\"GPKG\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06NtCpIYAy1N"
      },
      "source": [
        "<div class=\"alert alert-danger\">\n",
        "  <strong>CHALLENGE 1</strong>\n",
        "    <br> * Create a public repo named \"week2_spatial\" with its README file. (1 point)\n",
        "    <br> * Clone the repo to your computer. (1 point)\n",
        "    <br> * In the local repo in your computer, create a folder named \"data\". (1 point)\n",
        "    <br> * Get Three maps for the same country: the lines can be rivers, highways or similar; the points have to be airports; and the polygons  of the 2rd administrative division ('provinces' in Per, 'counties' in USA). Download those maps into the \"data\" folder. You can find airports here: https://ourairports.com/data/ (5 points)\n",
        "    <br> * Plot in one map the three layers of maps, including the code. (5 points)\n",
        "    <br> * Publish the three layer map. (3 points)\n",
        "    <br> * Update the README to offer a quick explanation, the data dictionary, and the link to the published map. (2 points)\n",
        "    <br> * Make sure the code is well organized (explanations, comments, no warnings, no python messages). (2 points)\n",
        "    \n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaTGEnNpAy1N"
      },
      "source": [
        "<div class=\"alert alert-danger\">\n",
        "  <strong>CHALLENGE 2</strong>\n",
        "    <br> * Create a public repo named week2_spatial with its README file. (1 point)\n",
        "    <br> * Clone the repo to your computer. (1 point)\n",
        "    <br> * In the local repo in your computer, create a folder named \"data\". (1 point)\n",
        "    <br> * Get for the provinces of Peru data for any variable of your concern, the variable has to be measured in several years (you need at least 3 measures if the measures were every 5 or 10 years, or 10 measures if taken yearly). (4 points)\n",
        "    <br> * Merge that data into the map of provinces of Peru. (3 points)\n",
        "    <br> * Plot two maps, one with the provinces that improved, and other with the ones that worsen, include the code. (3 points)\n",
        "    <br> * Publish the two maps. (3 points)\n",
        "    <br> * Update the README to offer a quick explanation, the data dictionary, and the link to the published map. (2 points)\n",
        "    <br> * Make sure the code is well organized (explanations, comments, no warnings, no python messages). (2 points)\n",
        "    \n",
        "</div>\n"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {
      "attach-environment": true,
      "summary": "test"
    },
    "colab": {
      "provenance": []
    },
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "toc-autonumbering": false
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
